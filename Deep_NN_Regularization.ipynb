{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3997fcf",
   "metadata": {
    "id": "d3997fcf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d39312ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d39312ee",
    "outputId": "bf92bb2c-029c-46a1-85f4-68f3317d6c7f"
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X_org = np.array(data[\"data\"]).T\n",
    "Y_org = np.array(np.matrix(list(data[\"target\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8048cccb",
   "metadata": {
    "id": "8048cccb"
   },
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_org)\n",
    "X_std = scaler.transform(X_org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "125ac73a",
   "metadata": {
    "id": "125ac73a"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    for i in range(1,len(layer_dims)):\n",
    "        #using Xavier initialization efficient using tanh activation.\n",
    "        np.random.seed(10)\n",
    "        parameters[\"W\"+ str(i)] = np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(2/(layer_dims[i-1]))\n",
    "        parameters[\"b\"+ str(i)] = np.zeros((layer_dims[i],1))\n",
    "    return parameters            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e3185c",
   "metadata": {
    "id": "b0e3185c"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca211668",
   "metadata": {
    "id": "ca211668"
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65108df4",
   "metadata": {
    "id": "65108df4"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    dG = (x>0).astype(int)\n",
    "    x = np.array(dG)*np.array(x)\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8d2c5358",
   "metadata": {
    "id": "8d2c5358"
   },
   "outputs": [],
   "source": [
    "def get_layer_values(A_prev,W,b, activation):\n",
    "    A_prev = A_prev\n",
    "    W = W\n",
    "    Z = np.dot(W,A_prev)+b\n",
    "    if activation ==1 or activation== \"sigmoid\":\n",
    "        A = sigmoid(Z)\n",
    "    elif activation == 2 or activation == \"tanh\":\n",
    "        A = tanh(Z)\n",
    "    elif activation == 3 or activation == \"relu\":\n",
    "        A = relu(Z)\n",
    "    linear_cache = (A_prev,W,b)\n",
    "    activation_cache = Z\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bd5655c5",
   "metadata": {
    "id": "bd5655c5"
   },
   "outputs": [],
   "source": [
    "def get_cost(Y,AL, caches, lambd):\n",
    "    m = Y.shape[1]\n",
    "    cost = -(np.dot(np.log(AL),Y.T)+np.dot(np.log(1-AL),(1-Y).T))*(1/m)\n",
    "    L = len(caches)\n",
    "    reg_cost = 0\n",
    "    for i in range(1,L+1):\n",
    "        reg_cost = np.sum(np.square(caches[i-1][0][1])) + reg_cost\n",
    "    return cost+ lambd*(reg_cost/(2*m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d64b0b09",
   "metadata": {
    "id": "d64b0b09"
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activation, lambd):\n",
    "    caches = []\n",
    "    A_prev = X\n",
    "    L = int(len(parameters)//2)\n",
    "    for i in range(1,L+1):\n",
    "        A,cache_temp = get_layer_values(A_prev= A_prev, W= parameters[\"W\"+ str(i)], b = parameters[\"b\"+ str(i)], activation = activation[i])\n",
    "        caches.append(cache_temp)\n",
    "        A_prev = A\n",
    "    cost = get_cost(Y =Y, AL = A, caches = caches, lambd = lambd)\n",
    "    cost = np.squeeze(cost)\n",
    "    AL = A\n",
    "    return AL, caches, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27124a77",
   "metadata": {
    "id": "27124a77"
   },
   "outputs": [],
   "source": [
    "def get_dZ(dA,cache,activation):\n",
    "    if activation == 1:\n",
    "        n = 1/(1+np.exp(cache[1]))\n",
    "        dG = n*(1-n)\n",
    "        dZ = dA*dG\n",
    "    elif activation == 2:\n",
    "        dG = 1-np.square(cache[1])\n",
    "        dZ = dA*dG\n",
    "    else:\n",
    "        dG = (cache[1]>0).astype(int)\n",
    "        dZ = dA*dG\n",
    "    return dZ     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8f86e0dc",
   "metadata": {
    "id": "8f86e0dc"
   },
   "outputs": [],
   "source": [
    "def backward_propagation(AL,Y, caches, activation,lambd):\n",
    "    grads = {}\n",
    "    dAL = -(np.divide(Y,AL)- np.divide(1-Y, 1-AL))\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    #Y = Y.reshape(AL.shape)\n",
    "    for i in reversed(range(L)):\n",
    "        grads[\"dW\"+ str(i+1)] = np.dot(get_dZ(dA= dAL,cache = caches[i], activation = activation[i+1]),caches[i][0][0].T)/m + ((lambd/m)*(caches[i][0][1]))\n",
    "        grads[\"db\"+ str(i+1)] = np.mean(get_dZ(dA = dAL,cache = caches[i], activation = activation[i+1]), axis = 1, keepdims = True)\n",
    "        grads[\"dA\"+ str(i)] = np.dot(caches[i][0][1].T,get_dZ(dA = dAL,cache = caches[i], activation = activation[i+1]))\n",
    "        dAL = grads[\"dA\"+ str(i)]\n",
    "    return grads    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c995b6",
   "metadata": {
    "id": "d5c995b6"
   },
   "outputs": [],
   "source": [
    "def update_parameters(grads, parameters, learning_rate):\n",
    "    updated_params = parameters.copy()\n",
    "    L = len(updated_params)\n",
    "    for i in range(1,((L//2)+1)):\n",
    "        updated_params[\"W\"+ str(i)] = parameters[\"W\"+ str(i)] - learning_rate*grads[\"dW\"+ str(i)]\n",
    "        updated_params[\"b\"+ str(i)] = parameters[\"b\"+ str(i)] - learning_rate*grads[\"db\"+ str(i)]\n",
    "    return updated_params    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7e6a2b16",
   "metadata": {
    "id": "7e6a2b16"
   },
   "outputs": [],
   "source": [
    "def L_layer_model(X,Y,layers_dims, learning_rate ,num_iter , activation,lambd, print_cost = False):\n",
    "    costs = []\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    for i in range(num_iter):\n",
    "        AL,caches, cost =forward_propagation(X,parameters, activation,lambd)\n",
    "        grads = backward_propagation(AL, Y, caches, activation,lambd)\n",
    "        parameters = update_parameters(grads, parameters, learning_rate)\n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 1000 == 0 or i == num_iter - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iter:\n",
    "            costs.append(cost)\n",
    "    return parameters, costs        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8c1577ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c1577ea",
    "outputId": "6e27296c-433d-4cd4-c78d-731ac58c86e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6871995821953196\n",
      "Cost after iteration 1000: 0.2368781417656064\n",
      "Cost after iteration 2000: 0.22716197076426478\n",
      "Cost after iteration 3000: 0.2205814674522127\n",
      "Cost after iteration 4000: 0.21631813703850755\n",
      "Cost after iteration 5000: 0.2132037856223899\n",
      "Cost after iteration 6000: 0.21076217533428004\n",
      "Cost after iteration 7000: 0.2087225114313231\n",
      "Cost after iteration 8000: 0.20632148015843943\n",
      "Cost after iteration 9000: 0.20325435744775136\n",
      "Cost after iteration 10000: 0.19570197082971846\n",
      "Cost after iteration 11000: 0.19423323660320732\n",
      "Cost after iteration 12000: 0.1885767400968159\n",
      "Cost after iteration 13000: 0.19250192200411115\n",
      "Cost after iteration 14000: 0.19176270257997485\n",
      "Cost after iteration 15000: 0.18668097156529415\n",
      "Cost after iteration 16000: 0.19092452750393157\n",
      "Cost after iteration 17000: 0.1917354974120675\n",
      "Cost after iteration 17999: 0.19753124003513847\n"
     ]
    }
   ],
   "source": [
    "final_params, costs = L_layer_model(X_std,Y_org, layers_dims = [30,20,3,1], learning_rate = 0.09, num_iter = 18000, activation = [0,3,3,1],lambd= 0.3 ,print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8L819z_k1sSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8L819z_k1sSe",
    "outputId": "d3e756e0-36da-47f1-b1c1-18f0149431de"
   },
   "outputs": [],
   "source": [
    "a = np.array(np.matrix(X[:,0])).T\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "SBaex3aVpbMr",
   "metadata": {
    "id": "SBaex3aVpbMr"
   },
   "outputs": [],
   "source": [
    "def predict(X, final_params, activation):\n",
    "    y = np.ones((1,X.shape[1]))\n",
    "    y = X\n",
    "    L = len(final_params)//2\n",
    "    for i in range(1,L+1):\n",
    "        A_prev = np.dot(final_params[\"W\"+str(i)],y) + final_params[\"b\"+ str(i)]\n",
    "        if activation[i] == 1:\n",
    "            A_prev = sigmoid(A_prev)\n",
    "        elif activation[i] == 2:\n",
    "            A_prev = tanh(A_prev)\n",
    "        elif activation[i] == 3:\n",
    "            A_prev = relu(A_prev)\n",
    "        y = A_prev\n",
    "        output = (y>0.5).astype(int)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "K-oR9T-VtvuW",
   "metadata": {
    "id": "K-oR9T-VtvuW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ljakka2\\AppData\\Local\\Temp\\ipykernel_1356\\4033946986.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "k = predict(X, final_params, activation = [0,3,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "OAC2mnjH7fWb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAC2mnjH7fWb",
    "outputId": "e079dcab-e882-4612-8c7b-0a5b4a6d4e4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9191564147627417"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range((X.shape[1])):\n",
    "    if k[:,i]==Y[:,i]:\n",
    "        count+=1\n",
    "accuracy = count/X.shape[1]\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
