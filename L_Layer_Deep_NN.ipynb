{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeshSreenathJ/L-Layer-Deep-NeuralNetwork/blob/main/L_Layer_Deep_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d3997fcf",
      "metadata": {
        "id": "d3997fcf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d39312ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d39312ee",
        "outputId": "52e15d5c-4f8a-423f-efb0-29a1de2c07ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 569)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = load_breast_cancer()\n",
        "X = np.array(data[\"data\"]).T\n",
        "Y = np.array(np.matrix(list(data[\"target\"])))\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8048cccb",
      "metadata": {
        "id": "8048cccb"
      },
      "outputs": [],
      "source": [
        "#Normalize the data\n",
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "X_std = scaler.transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "125ac73a",
      "metadata": {
        "id": "125ac73a"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(layer_dims):\n",
        "    parameters = {}\n",
        "    for i in range(1,len(layer_dims)):\n",
        "        #using Xavier initialization efficient using tanh activation.\n",
        "        np.random.seed(10)\n",
        "        parameters[\"W\"+ str(i)] = np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(1/(layer_dims[i-1]))\n",
        "        parameters[\"b\"+ str(i)] = np.zeros((layer_dims[i],1))\n",
        "    return parameters            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b0e3185c",
      "metadata": {
        "id": "b0e3185c"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ca211668",
      "metadata": {
        "id": "ca211668"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "65108df4",
      "metadata": {
        "id": "65108df4"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    dG = (x>0).astype(int)\n",
        "    x = np.array(dG)*np.array(x)\n",
        "    return x    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d2c5358",
      "metadata": {
        "id": "8d2c5358"
      },
      "outputs": [],
      "source": [
        "def get_layer_values(A_prev,W,b, activation):\n",
        "    Z = np.dot(W,A_prev)+b\n",
        "    if activation ==1 or activation== \"sigmoid\":\n",
        "        A = sigmoid(Z)\n",
        "    elif activation == 2 or activation == \"tanh\":\n",
        "        A = tanh(Z)\n",
        "    elif activation == 3 or activation == \"relu\":\n",
        "        A = relu(Z)\n",
        "    linear_cache = (A_prev,W,b)\n",
        "    activation_cache = Z\n",
        "    cache = (linear_cache, activation_cache)\n",
        "    return A, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bd5655c5",
      "metadata": {
        "id": "bd5655c5"
      },
      "outputs": [],
      "source": [
        "def get_cost(Y,AL):\n",
        "    m = Y.shape[1]\n",
        "    cost = -(np.dot(np.log(AL),Y.T)+np.dot(np.log(1-AL),(1-Y).T))*(1/m)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d64b0b09",
      "metadata": {
        "id": "d64b0b09"
      },
      "outputs": [],
      "source": [
        "def forward_propagation(X, parameters, activation):\n",
        "    caches = []\n",
        "    A_prev = X\n",
        "    L = int(len(parameters)//2)\n",
        "    for i in range(1,L+1):\n",
        "        A,cache_temp = get_layer_values(A_prev= A_prev, W= parameters[\"W\"+ str(i)], b = parameters[\"b\"+ str(i)], activation = activation[i])\n",
        "        caches.append(cache_temp)\n",
        "        A_prev = A\n",
        "    cost = get_cost(Y, AL = A)\n",
        "    cost = np.squeeze(cost)\n",
        "    AL = A\n",
        "    return AL, caches, cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "27124a77",
      "metadata": {
        "id": "27124a77"
      },
      "outputs": [],
      "source": [
        "def get_dZ(dA,cache,activation):\n",
        "    if activation == 1:\n",
        "        n = 1/(1+np.exp(cache[1]))\n",
        "        dG = n*(1-n)\n",
        "        dZ = dA*dG\n",
        "    elif activation == 2:\n",
        "        dG = 1-np.square(cache[1])\n",
        "        dZ = dA*dG\n",
        "    else:\n",
        "        dG = (cache[1]>0).astype(int)\n",
        "        dZ = dA*dG\n",
        "    return dZ     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8f86e0dc",
      "metadata": {
        "id": "8f86e0dc"
      },
      "outputs": [],
      "source": [
        "def backward_propagation(AL,Y, caches, activation):\n",
        "    grads = {}\n",
        "    dAL = -(np.divide(Y,AL)- np.divide(1-Y, 1-AL))\n",
        "    L = len(caches)\n",
        "    m = AL.shape[1]\n",
        "    #Y = Y.reshape(AL.shape)\n",
        "    for i in reversed(range(L)):\n",
        "        grads[\"dW\"+ str(i+1)] = np.dot(get_dZ(dA= dAL,cache = caches[i], activation = activation[i+1]),caches[i][0][0].T)/m\n",
        "        grads[\"db\"+ str(i+1)] = np.mean(get_dZ(dA = dAL,cache = caches[i], activation = activation[i+1]), axis = 1, keepdims = True)\n",
        "        grads[\"dA\"+ str(i)] = np.dot(caches[i][0][1].T,get_dZ(dA = dAL,cache = caches[i], activation = activation[i+1]))\n",
        "        dAL = grads[\"dA\"+ str(i)]\n",
        "    return grads    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d5c995b6",
      "metadata": {
        "id": "d5c995b6"
      },
      "outputs": [],
      "source": [
        "def update_parameters(grads, parameters, learning_rate):\n",
        "    updated_params = parameters.copy()\n",
        "    L = len(updated_params)\n",
        "    for i in range(1,((L//2)+1)):\n",
        "        updated_params[\"W\"+ str(i)] = parameters[\"W\"+ str(i)] - learning_rate*grads[\"dW\"+ str(i)]\n",
        "        updated_params[\"b\"+ str(i)] = parameters[\"b\"+ str(i)] - learning_rate*grads[\"db\"+ str(i)]\n",
        "    return updated_params    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7e6a2b16",
      "metadata": {
        "id": "7e6a2b16"
      },
      "outputs": [],
      "source": [
        "def L_layer_model(X,Y,layers_dims, learning_rate ,num_iter , activation, print_cost = False):\n",
        "    costs = []\n",
        "    parameters = initialize_parameters(layers_dims)\n",
        "    for i in range(num_iter):\n",
        "        AL,caches, cost =forward_propagation(X,parameters, activation)\n",
        "        grads = backward_propagation(AL, Y, caches, activation)\n",
        "        parameters = update_parameters(grads, parameters, learning_rate)\n",
        "        # Print the cost every 100 iterations\n",
        "        if print_cost and i % 100 == 0 or i == num_iter - 1:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "        if i % 100 == 0 or i == num_iter:\n",
        "            costs.append(cost)\n",
        "    return parameters, costs        \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8c1577ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1577ea",
        "outputId": "875e516c-8b00-4569-9117-e0675aaa3746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.6986633028756489\n",
            "Cost after iteration 100: 0.6444094792749455\n",
            "Cost after iteration 200: 0.5657049532817655\n",
            "Cost after iteration 300: 0.5319899886155737\n",
            "Cost after iteration 400: 0.4666205819515491\n",
            "Cost after iteration 500: 0.4044785942220556\n",
            "Cost after iteration 600: 0.35213191297190705\n",
            "Cost after iteration 700: 0.32568579688514787\n",
            "Cost after iteration 800: 0.3054088595245856\n",
            "Cost after iteration 900: 0.2860144569978596\n",
            "Cost after iteration 1000: 0.28049550091663183\n",
            "Cost after iteration 1100: 0.2683444219416358\n",
            "Cost after iteration 1200: 0.2559525286669425\n",
            "Cost after iteration 1300: 0.24289809095630543\n",
            "Cost after iteration 1400: 0.25603050251922915\n",
            "Cost after iteration 1500: 0.24485773538442332\n",
            "Cost after iteration 1600: 0.2536806090076019\n",
            "Cost after iteration 1700: 0.23521729982938092\n",
            "Cost after iteration 1800: 0.2293865716251471\n",
            "Cost after iteration 1900: 0.22635860556866874\n",
            "Cost after iteration 2000: 0.22109756076753667\n",
            "Cost after iteration 2100: 0.22192526837202048\n",
            "Cost after iteration 2200: 0.21414433218794435\n",
            "Cost after iteration 2300: 0.2128674214064703\n",
            "Cost after iteration 2400: 0.20981829410359065\n",
            "Cost after iteration 2500: 0.20605414015827397\n",
            "Cost after iteration 2600: 0.22346318472439913\n",
            "Cost after iteration 2699: 0.2077302465286428\n"
          ]
        }
      ],
      "source": [
        "final_params, costs = L_layer_model(X_std,Y, layers_dims = [30,10,7,5,3,1], learning_rate = 0.06, num_iter = 2700, activation = [0,3,3,3,3,1], print_cost = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "SBaex3aVpbMr",
      "metadata": {
        "id": "SBaex3aVpbMr"
      },
      "outputs": [],
      "source": [
        "def predict(X, final_params, activation):\n",
        "    y = np.ones((1,X.shape[1]))\n",
        "    y = X\n",
        "    L = len(final_params)//2\n",
        "    for i in range(1,L+1):\n",
        "        A_prev = np.dot(final_params[\"W\"+str(i)],y) + final_params[\"b\"+ str(i)]\n",
        "        if activation[i] == 1:\n",
        "            A_prev = sigmoid(A_prev)\n",
        "        elif activation[i] == 2:\n",
        "            A_prev = tanh(A_prev)\n",
        "        elif activation[i] == 3:\n",
        "            A_prev = relu(A_prev)\n",
        "        y = A_prev\n",
        "        output = (y>0.5).astype(int)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "K-oR9T-VtvuW",
      "metadata": {
        "id": "K-oR9T-VtvuW"
      },
      "outputs": [],
      "source": [
        "k = predict(X, final_params, activation = [0,3,3,3,3,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "OAC2mnjH7fWb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAC2mnjH7fWb",
        "outputId": "dca8dccb-89c0-4fdb-8afe-4b6cbb5bfba5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8804920913884007"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "count = 0\n",
        "for i in range((X.shape[1])):\n",
        "    if k[:,i]==Y[:,i]:\n",
        "        count+=1\n",
        "accuracy = count/X.shape[1]\n",
        "accuracy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}